{
 "metadata": {
  "name": "",
  "signature": "sha256:18f580e9d99dc94df2432af969b8d3c39b5b559a3f40767dc6e503afcb853693"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import SparkContext\n",
      "sc=SparkContext('local','classify')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rawData=sc.textFile('/home/zz/Desktop/PycharmProjects/machine learning/kaggle/kaggle  stumbleupon/data/train_noheader.tsv')\n",
      "records=rawData.map(lambda x:x.split('\\t'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print records.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'\"http://www.bloomberg.com/news/2010-12-23/ibm-predicts-holographic-calls-air-breathing-batteries-by-2015.html\"', u'\"4042\"', u'\"{\"\"title\"\":\"\"IBM Sees Holographic Calls Air Breathing Batteries ibm sees holographic calls, air-breathing batteries\"\",\"\"body\"\":\"\"A sign stands outside the International Business Machines Corp IBM Almaden Research Center campus in San Jose California Photographer Tony Avelar Bloomberg Buildings stand at the International Business Machines Corp IBM Almaden Research Center campus in the Santa Teresa Hills of San Jose California Photographer Tony Avelar Bloomberg By 2015 your mobile phone will project a 3 D image of anyone who calls and your laptop will be powered by kinetic energy At least that s what International Business Machines Corp sees in its crystal ball The predictions are part of an annual tradition for the Armonk New York based company which surveys its 3 000 researchers to find five ideas expected to take root in the next five years IBM the world s largest provider of computer services looks to Silicon Valley for input gleaning many ideas from its Almaden research center in San Jose California Holographic conversations projected from mobile phones lead this year s list The predictions also include air breathing batteries computer programs that can tell when and where traffic jams will take place environmental information generated by sensors in cars and phones and cities powered by the heat thrown off by computer servers These are all stretch goals and that s good said Paul Saffo managing director of foresight at the investment advisory firm Discern in San Francisco In an era when pessimism is the new black a little dose of technological optimism is not a bad thing For IBM it s not just idle speculation The company is one of the few big corporations investing in long range research projects and it counts on innovation to fuel growth Saffo said Not all of its predictions pan out though IBM was overly optimistic about the spread of speech technology for instance When the ideas do lead to products they can have broad implications for society as well as IBM s bottom line he said Research Spending They have continued to do research when all the other grand research organizations are gone said Saffo who is also a consulting associate professor at Stanford University IBM invested 5 8 billion in research and development last year 6 1 percent of revenue While that s down from about 10 percent in the early 1990s the company spends a bigger share on research than its computing rivals Hewlett Packard Co the top maker of personal computers spent 2 4 percent last year At Almaden scientists work on projects that don t always fit in with IBM s computer business The lab s research includes efforts to develop an electric car battery that runs 500 miles on one charge a filtration system for desalination and a program that shows changes in geographic data IBM rose 9 cents to 146 04 at 11 02 a m in New York Stock Exchange composite trading The stock had gained 11 percent this year before today Citizen Science The list is meant to give a window into the company s innovation engine said Josephine Cheng a vice president at IBM s Almaden lab All this demonstrates a real culture of innovation at IBM and willingness to devote itself to solving some of the world s biggest problems she said Many of the predictions are based on projects that IBM has in the works One of this year s ideas that sensors in cars wallets and personal devices will give scientists better data about the environment is an expansion of the company s citizen science initiative Earlier this year IBM teamed up with the California State Water Resources Control Board and the City of San Jose Environmental Services to help gather information about waterways Researchers from Almaden created an application that lets smartphone users snap photos of streams and creeks and report back on conditions The hope is that these casual observations will help local and state officials who don t have the resources to do the work themselves Traffic Predictors IBM also sees data helping shorten commutes in the next five years Computer programs will use algorithms and real time traffic information to predict which roads will have backups and how to avoid getting stuck Batteries may last 10 times longer in 2015 than today IBM says Rather than using the current lithium ion technology new models could rely on energy dense metals that only need to interact with the air to recharge Some electronic devices might ditch batteries altogether and use something similar to kinetic wristwatches which only need to be shaken to generate a charge The final prediction involves recycling the heat generated by computers and data centers Almost half of the power used by data centers is currently spent keeping the computers cool IBM scientists say it would be better to harness that heat to warm houses and offices In IBM s first list of predictions compiled at the end of 2006 researchers said instantaneous speech translation would become the norm That hasn t happened yet While some programs can quickly translate electronic documents and instant messages and other apps can perform limited speech translation there s nothing widely available that acts like the universal translator in Star Trek Second Life The company also predicted that online immersive environments such as Second Life would become more widespread While immersive video games are as popular as ever Second Life s growth has slowed Internet users are flocking instead to the more 2 D environments of Facebook Inc and Twitter Inc Meanwhile a 2007 prediction that mobile phones will act as a wallet ticket broker concierge bank and shopping assistant is coming true thanks to the explosion of smartphone applications Consumers can pay bills through their banking apps buy movie tickets and get instant feedback on potential purchases all with a few taps on their phones The nice thing about the list is that it provokes thought Saffo said If everything came true they wouldn t be doing their job To contact the reporter on this story Ryan Flinn in San Francisco at rflinn bloomberg net To contact the editor responsible for this story Tom Giles at tgiles5 bloomberg net by 2015, your mobile phone will project a 3-d image of anyone who calls and your laptop will be powered by kinetic energy. at least that\\\\u2019s what international business machines corp. sees in its crystal ball.\"\",\"\"url\"\":\"\"bloomberg news 2010 12 23 ibm predicts holographic calls air breathing batteries by 2015 html\"\"}\"', u'\"business\"', u'\"0.789131\"', u'\"2.055555556\"', u'\"0.676470588\"', u'\"0.205882353\"', u'\"0.047058824\"', u'\"0.023529412\"', u'\"0.443783175\"', u'\"0\"', u'\"0\"', u'\"0.09077381\"', u'\"0\"', u'\"0.245831182\"', u'\"0.003883495\"', u'\"1\"', u'\"1\"', u'\"24\"', u'\"0\"', u'\"5424\"', u'\"170\"', u'\"8\"', u'\"0.152941176\"', u'\"0.079129575\"', u'\"0\"']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.regression import LabeledPoint\n",
      "from pyspark.mllib.linalg import Vectors\n",
      "trimmed = records.map(lambda x: [xx.replace('\\\"','') for xx in x])\n",
      "trimmed.take(1)\n",
      "label = trimmed.map(lambda x : x[-1])\n",
      "\n",
      "data = trimmed.map(lambda x : (x[-1],x[4:-1])).\\\n",
      "               map(lambda (x,y):(x.replace('\\\"',''),[0.0 if yy=='\\\"?\\\"' else yy.replace('\\\"','') for yy in y])).\\\n",
      "               map(lambda (x,y):(x.replace(\"\\\"\",\"\"),[0.0 if yy =='?' else yy.replace(\"\\\"\",\"\") for yy in y])).\\\n",
      "               map(lambda (x,y):(int(x), [float(yy) for yy in y])).\\\n",
      "               map(lambda (x,y):LabeledPoint(x,Vectors.dense(y)))\n",
      "data.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[LabeledPoint(0.0, [0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575]),\n",
        " LabeledPoint(1.0, [0.574147,3.677966102,0.50802139,0.288770053,0.213903743,0.144385027,0.468648998,0.0,0.0,0.098707403,0.0,0.203489628,0.088652482,1.0,1.0,40.0,0.0,4973.0,187.0,9.0,0.181818182,0.125448029]),\n",
        " LabeledPoint(1.0, [0.996526,2.382882883,0.562015504,0.321705426,0.120155039,0.042635659,0.525448029,0.0,0.0,0.072447859,0.0,0.22640177,0.120535714,1.0,1.0,55.0,0.0,2240.0,258.0,11.0,0.166666667,0.057613169]),\n",
        " LabeledPoint(1.0, [0.801248,1.543103448,0.4,0.1,0.016666667,0.0,0.480724749,0.0,0.0,0.095860566,0.0,0.265655744,0.035343035,1.0,0.0,24.0,0.0,2737.0,120.0,5.0,0.041666667,0.100858369]),\n",
        " LabeledPoint(0.0, [0.719157,2.676470588,0.5,0.222222222,0.12345679,0.043209877,0.446143274,0.0,0.0,0.024908425,0.0,0.228887247,0.050473186,1.0,1.0,14.0,0.0,12032.0,162.0,10.0,0.098765432,0.082568807])]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.cache()\n",
      "numData = data.count()\n",
      "print numData"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7395\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbdata = trimmed.map(lambda x : (x[-1],x[4:-1])).\\\n",
      "                 map(lambda (x,y):(x.replace('\\\"',''),[0.0 if yy=='\\\"?\\\"' else yy.replace('\\\"','') for yy in y])).\\\n",
      "                 map(lambda (x,y):(x.replace(\"\\\"\",\"\"),[0.0 if yy =='?' else yy.replace(\"\\\"\",\"\") for yy in y])).\\\n",
      "                 map(lambda (x,y):(int(x), [float(yy) for yy in y])).\\\n",
      "                 map(lambda (x,y):(x, [0.0 if yy<0 else yy for yy in y])).\\\n",
      "                 map(lambda (x,y):LabeledPoint(x,Vectors.dense(y)))\n",
      "nbdata.take(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[LabeledPoint(0.0, [0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575]),\n",
        " LabeledPoint(1.0, [0.574147,3.677966102,0.50802139,0.288770053,0.213903743,0.144385027,0.468648998,0.0,0.0,0.098707403,0.0,0.203489628,0.088652482,1.0,1.0,40.0,0.0,4973.0,187.0,9.0,0.181818182,0.125448029])]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u5bfc\u5165\u76f8\u5e94\u7684\u7c7b\n",
      "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
      "from pyspark.mllib.classification import SVMWithSGD\n",
      "from pyspark.mllib.classification import NaiveBayes\n",
      "from pyspark.mllib.tree import DecisionTree\n",
      "\n",
      "numIteration = 10   #\u8fed\u4ee3\u6b21\u6570\n",
      "maxTreeDepth = 5    #\u6811\u7684\u6df1\u5ea6\n",
      "\n",
      "numClass = label.distinct().count()     #\u7c7b\u522b\u6570\n",
      "print '\u7c7b\u522b\u6570\uff1a',numClass\n",
      "\n",
      "#\u8bad\u7ec3\u903b\u8f91\u56de\u5f52\u3001\u652f\u6301\u5411\u91cf\u673a\u3001\u6734\u7d20\u8d1d\u53f6\u65af\u548c\u51b3\u7b56\u6811\u6a21\u578b\n",
      "lrModel = LogisticRegressionWithSGD.train(data, numIteration)\n",
      "svmModel = SVMWithSGD.train(data, numIteration)\n",
      "nbModel = NaiveBayes.train(nbdata)\n",
      "dtModel = DecisionTree.trainClassifier(data,numClass,{},impurity='entropy', maxDepth=maxTreeDepth)\n",
      "print '\u903b\u8f91\u56de\u5f52\u6a21\u578b\u53c2\u6570\uff1a',lrModel\n",
      "print '\u652f\u6301\u5411\u91cf\u673a\u6a21\u578b\u53c2\u6570\uff1a',svmModel\n",
      "print '\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u53c2\u6570\uff1a',nbModel\n",
      "print '\u51b3\u7b56\u6811\u6a21\u578b\u53c2\u6570\uff1a',dtModel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u7c7b\u522b\u6570\uff1a 2\n",
        "\u903b\u8f91\u56de\u5f52\u6a21\u578b\u53c2\u6570\uff1a"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (weights=[-0.110216274454,-0.493200344739,-0.0712665620384,-0.0214744216778,0.00276706475384,0.00246385887598,-1.33300460292,0.0525232672351,0.0,-0.0320576776,-0.00653638798541,-0.0613702511674,-0.14975863133,-0.13648187383,-0.121161700009,-15.6451616669,-0.0177690355464,745.987958686,-7.73567729685,-1.38587998188,-0.0355600416613,-0.0352085128613], intercept=0.0)\n",
        "\u652f\u6301\u5411\u91cf\u673a\u6a21\u578b\u53c2\u6570\uff1a (weights=[-0.122188386978,-0.527510758159,-0.0742371782434,-0.0206667449306,0.00546395033577,0.00409811283781,-1.54824523474,0.0607028905087,0.0,-0.037008323802,-0.007374037142,-0.067970375864,-0.172289581054,-0.148716595522,-0.129369384966,-18.0315472516,-0.0202704220321,1025.48043141,-5.05188911633,-1.54111193167,-0.038689478606,-0.0397619278886], intercept=0.0)\n",
        "\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u53c2\u6570\uff1a <pyspark.mllib.classification.NaiveBayesModel object at 0x7fbbf83bfc50>\n",
        "\u51b3\u7b56\u6811\u6a21\u578b\u53c2\u6570\uff1a DecisionTreeModel classifier of depth 5 with 61 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/mllib/classification.py:313: UserWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
        "  \"Deprecated in 2.0.0. Use ml.classification.LogisticRegression or \"\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataPoint = data.first()\n",
      "prediction = lrModel.predict(dataPoint.features)\n",
      "print '\u9884\u6d4b\u7684\u7c7b\u522b\uff1a',prediction\n",
      "print '\u771f\u5b9e\u7684\u7c7b\u522b\uff1a',int(dataPoint.label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u9884\u6d4b\u7684\u7c7b\u522b\uff1a 1\n",
        "\u771f\u5b9e\u7684\u7c7b\u522b\uff1a 0\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = lrModel.predict(data.map(lambda x : x.features))\n",
      "print '\u524d\u5341\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u6807\u7b7e\uff1a',predictions.take(10)\n",
      "print '\u524d\u5341\u4e2a\u6837\u672c\u7684\u771f\u5b9e\u6807\u7b7e\uff1a',data.map(lambda x : x.label).map(lambda x: int(x)).take(10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u524d\u5341\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u6807\u7b7e\uff1a "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "\u524d\u5341\u4e2a\u6837\u672c\u7684\u771f\u5b9e\u6807\u7b7e\uff1a "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u903b\u8f91\u56de\u5f52\u6a21\u578b\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u6570\u76ee\n",
      "lrTotalCorrect = data.map(lambda point : 1 if(lrModel.predict(point.features)==point.label) else 0).sum()\n",
      "#\u652f\u6301\u5411\u91cf\u673a\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u6570\u76ee\n",
      "svmTotalCorrect = data.map(lambda point : 1 if(svmModel.predict(point.features)==point.label) else 0).sum()\n",
      "#\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u6570\u76ee\n",
      "nbTotalCorrect = nbdata.map(lambda point : 1 if (nbModel.predict(point.features) == point.label) else 0).sum()\n",
      "\n",
      "#\u51b3\u7b56\u6811\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u6570\u76ee\n",
      "predictLabel= dtModel.predict(data.map(lambda point: point.features)).collect()\n",
      "trueLabel = data.map(lambda point: point.label).collect()\n",
      "dtTotalCorrect = sum([1.0 if prediction == trueLabel[i] else 0.0 for i, prediction in enumerate(predictLabel)])\n",
      "\n",
      "#\u903b\u8f91\u56de\u5f52\u6a21\u578b\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387\n",
      "lrAccuracy = lrTotalCorrect/(data.count()*1.0)\n",
      "#\u652f\u6301\u5411\u91cf\u673a\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387\n",
      "svmAccuracy = svmTotalCorrect/(data.count()*1.0)\n",
      "#\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387\n",
      "nbAccuracy = nbTotalCorrect/(1.0*nbdata.count())\n",
      "#\u51b3\u7b56\u6811\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387\n",
      "dtAccuracy = dtTotalCorrect/(1.0*data.count())\n",
      "print '\u603b\u5171\u7684\u6837\u672c\u6570\u76ee: %s'%data.count()\n",
      "print '\u903b\u8f91\u56de\u5f52\u6a21\u578b\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387: %s'%lrAccuracy\n",
      "print '\u652f\u6301\u5411\u91cf\u673a\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387: %f'%svmAccuracy\n",
      "print '\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387: %f'%nbAccuracy\n",
      "print '\u51b3\u7b56\u6811\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387: %f'%dtAccuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u603b\u5171\u7684\u6837\u672c\u6570\u76ee: 7395\n",
        "\u903b\u8f91\u56de\u5f52\u6a21\u578b\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387: 0.514672075727\n",
        "\u652f\u6301\u5411\u91cf\u673a\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387: 0.514672\n",
        "\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387: 0.580392\n",
        "\u51b3\u7b56\u6811\u6a21\u578b\u7684\u9884\u6d4b\u6b63\u786e\u7387: 0.648276\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u6a21\u578b\u8bc4\u4ef7 \u51c6\u786e\u7387 \u53ec\u56de\u7387\n",
      "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
      "all_models_metrics = []\n",
      "for model in [lrModel, svmModel]:\n",
      "    scoresAndLabels = data.map(lambda point:(model.predict(point.features), point.label)).collect()\n",
      "    scoresAndLabels = [[float(i),j] for i,j in scoresAndLabels]\n",
      "    \n",
      "    rdd_scoresAndLabels = sc.parallelize(scoresAndLabels)   #\u5c06\u6570\u636e\u8f6c\u6362\u4e3ardd\n",
      "    metrics = BinaryClassificationMetrics(rdd_scoresAndLabels)\n",
      "    all_models_metrics.append((model.__class__.__name__, metrics.areaUnderROC, metrics.areaUnderPR))\n",
      "\n",
      "for modelName, AUC, PR in all_models_metrics:\n",
      "    print '%s\u7684AUC\u662f%f,PR\u662f%f'%(modelName, AUC, PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LogisticRegressionModel\u7684AUC\u662f0.501418,PR\u662f0.756759\n",
        "SVMModel\u7684AUC\u662f0.501418,PR\u662f0.756759\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scoresAndLabels = nbdata.map(lambda point:(nbModel.predict(point.features), point.label)).collect()\n",
      "scoresAndLabels = [[float(i),j] for i,j in scoresAndLabels]\n",
      "\n",
      "rdd_scoresAndLabels = sc.parallelize(scoresAndLabels)   #\u5c06\u6570\u636e\u8f6c\u6362\u4e3ardd\n",
      "nb_metric = BinaryClassificationMetrics(rdd_scoresAndLabels)\n",
      "\n",
      "print '%s\u7684AUC\u662f%f,PR\u662f%f'%(nbModel.__class__.__name__, nb_metric.areaUnderROC, nb_metric.areaUnderPR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NaiveBayesModel\u7684AUC\u662f0.583559,PR\u662f0.680851\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictionLabels = dtModel.predict(data.map(lambda point: point.features)).collect()\n",
      "trueLabels = data.map(lambda point: point.label).collect()\n",
      "scoresAndLabels = [[prediction, trueLabel] for prediction,trueLabel in zip(predictionLabels, trueLabels)]\n",
      "scoresAndLabels = [[float(i),j] for i,j in scoresAndLabels]\n",
      "rdd_scoresAndLabels = sc.parallelize(scoresAndLabels)\n",
      "\n",
      "dt_metric = BinaryClassificationMetrics(rdd_scoresAndLabels)\n",
      "print '%s\u7684AUC\u662f%f,PR\u662f%f'%(dtModel.__class__.__name__, dt_metric.areaUnderROC, dt_metric.areaUnderPR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTreeModel\u7684AUC\u662f0.648837,PR\u662f0.743081\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u7279\u5f81\u6807\u51c6\u5316\n",
      "from pyspark.mllib.stat import MultivariateStatisticalSummary\n",
      "from pyspark.mllib.linalg.distributed import RowMatrix\n",
      "\n",
      "vectors = data.map(lambda point : point.features)\n",
      "matrix = MultivariateStatisticalSummary(vectors)\n",
      "matrix_mean = matrix.mean()\n",
      "matrix_min = matrix.min()\n",
      "print '\u6570\u636e\u96c6\u6bcf\u5217\u7684\u5747\u503c:',matrix_mean\n",
      "print '\u6570\u636e\u96c6\u6bcf\u5217\u7684\u6700\u5c0f\u503c:',matrix_min\n",
      "print '\u6570\u636e\u96c6\u6bcf\u5217\u7684\u6700\u5927\u503c:',matrix.max()\n",
      "print '\u6570\u636e\u96c6\u7684\u6837\u672c\u6570:',matrix.count()\n",
      "print '\u6570\u636e\u96c6\u6bcf\u5217\u7684\u65b9\u5dee:',matrix.variance()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u6570\u636e\u96c6\u6bcf\u5217\u7684\u5747\u503c: [  4.12258053e-01   2.76182319e+00   4.68230473e-01   2.14079926e-01\n",
        "   9.20623607e-02   4.92621604e-02   2.25510345e+00  -1.03750428e-01\n",
        "   0.00000000e+00   5.64227450e-02   2.12305612e-02   2.33778177e-01\n",
        "   2.75709037e-01   6.15551048e-01   6.60311021e-01   3.00770791e+01\n",
        "   3.97565923e-02   5.71659824e+03   1.78754564e+02   4.96064909e+00\n",
        "   1.72864050e-01   1.01220792e-01]\n",
        "\u6570\u636e\u96c6\u6bcf\u5217\u7684\u6700\u5c0f\u503c: [  0.00000000e+00   2.15028902e+00   5.80327869e-01   1.70491803e-01\n",
        "   9.83606600e-03   0.00000000e+00   3.08166410e-01   0.00000000e+00\n",
        "   0.00000000e+00   5.92044400e-02   1.00000000e+00   1.97932267e-01\n",
        "   9.67741940e-02   1.00000000e+00   0.00000000e+00   2.40000000e+01\n",
        "   0.00000000e+00   6.34200000e+03   3.05000000e+02   4.00000000e+00\n",
        "   3.27868850e-02   4.18563923e-01]\n",
        "\u6570\u636e\u96c6\u6bcf\u5217\u7684\u6700\u5927\u503c: [  5.77423000e-01   4.10788382e+00   6.47773279e-01   4.81781377e-01\n",
        "   3.52226721e-01   1.70040486e-01   5.68597561e-01   0.00000000e+00\n",
        "   0.00000000e+00   6.03566530e-02   0.00000000e+00   2.03655689e-01\n",
        "   1.09947644e-01   1.00000000e+00   1.00000000e+00   9.70000000e+01\n",
        "   0.00000000e+00   1.72000000e+02   2.47000000e+02   2.00000000e+00\n",
        "   1.13360324e-01   4.59183670e-02]\n",
        "\u6570\u636e\u96c6\u7684\u6837\u672c\u6570: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7395\n",
        "\u6570\u636e\u96c6\u6bcf\u5217\u7684\u65b9\u5dee: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  1.09727602e-01   7.42907773e+01   4.12575900e-02   2.15305244e-02\n",
        "   9.21057177e-03   5.27422016e-03   3.25347870e+01   9.39571798e-02\n",
        "   0.00000000e+00   1.71750875e-03   2.07798245e-02   2.75446690e-03\n",
        "   3.68329077e+00   2.36647955e-01   2.24300377e-01   4.15822321e+02\n",
        "   3.81760057e-02   7.87626486e+07   3.22037609e+04   1.04515955e+01\n",
        "   3.35890913e-02   6.27668400e-03]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.feature import StandardScalerModel,StandardScaler\n",
      "\n",
      "scaler = StandardScaler(withMean=True, withStd=True).fit(vectors)\n",
      "labels = data.map(lambda point: point.label)\n",
      "features = data.map(lambda point: point.features)\n",
      "print '\u539f\u59cb\u6570\u636e:',features.take(3)\n",
      "scaled_data = labels.zip(scaler.transform(features))\n",
      "scaled_data = scaled_data.map(lambda (x,y): LabeledPoint(x,y))\n",
      "print '\u89c4\u8303\u5316\u4e4b\u540e\u7684\u6570\u636e:',scaled_data.map(lambda point: point.features).take(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u539f\u59cb\u6570\u636e: [DenseVector([0.7891, 2.0556, 0.6765, 0.2059, 0.0471, 0.0235, 0.4438, 0.0, 0.0, 0.0908, 0.0, 0.2458, 0.0039, 1.0, 1.0, 24.0, 0.0, 5424.0, 170.0, 8.0, 0.1529, 0.0791]), DenseVector([0.5741, 3.678, 0.508, 0.2888, 0.2139, 0.1444, 0.4686, 0.0, 0.0, 0.0987, 0.0, 0.2035, 0.0887, 1.0, 1.0, 40.0, 0.0, 4973.0, 187.0, 9.0, 0.1818, 0.1254]), DenseVector([0.9965, 2.3829, 0.562, 0.3217, 0.1202, 0.0426, 0.5254, 0.0, 0.0, 0.0724, 0.0, 0.2264, 0.1205, 1.0, 1.0, 55.0, 0.0, 2240.0, 258.0, 11.0, 0.1667, 0.0576])]\n",
        "\u89c4\u8303\u5316\u4e4b\u540e\u7684\u6570\u636e:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [DenseVector([1.1376, -0.0819, 1.0251, -0.0559, -0.4689, -0.3543, -0.3175, 0.3385, 0.0, 0.8288, -0.1473, 0.2296, -0.1416, 0.7902, 0.7172, -0.298, -0.2035, -0.033, -0.0488, 0.9401, -0.1087, -0.2788]), DenseVector([0.4887, 0.1063, 0.1959, 0.509, 1.2695, 1.3097, -0.3132, 0.3385, 0.0, 1.0202, -0.1473, -0.5771, -0.0975, 0.7902, 0.7172, 0.4866, -0.2035, -0.0838, 0.0459, 1.2494, 0.0489, 0.3058]), DenseVector([1.7637, -0.044, 0.4617, 0.7334, 0.2927, -0.0912, -0.3032, 0.3385, 0.0, 0.3867, -0.1473, -0.1405, -0.0808, 0.7902, 0.7172, 1.2221, -0.2035, -0.3917, 0.4416, 1.868, -0.0338, -0.5504])]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lrModel_scaled = LogisticRegressionWithSGD.train(scaled_data,numIteration)\n",
      "lrPredictionLabel = lrModel_scaled.predict(scaled_data.map(lambda point: point.features))\n",
      "trueLabel = scaled_data.map(lambda point: point.label)\n",
      "lrTotalCorrect_scaled = sum([1.0 if prediction==label else 0.0 \\\n",
      "                             for prediction, label in zip(lrPredictionLabel.collect(),trueLabel.collect())])\\\n",
      "                        /scaled_data.count()\n",
      "print '\u7279\u5f81\u89c4\u8303\u5316\u4e4b\u540e\u903b\u8f91\u56de\u5f52\u9884\u6d4b\u7684\u6b63\u786e\u7387:',lrTotalCorrect_scaled"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u7279\u5f81\u89c4\u8303\u5316\u4e4b\u540e\u903b\u8f91\u56de\u5f52\u9884\u6d4b\u7684\u6b63\u786e\u7387: 0.620960108181\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_models_metrics =[]\n",
      "for model in [lrModel_scaled]:\n",
      "    scoresAndLabels = scaled_data.map(lambda point:(model.predict(point.features),point.label)).collect()\n",
      "    scoresAndLabels = [(float(i),j) for (i,j) in scoresAndLabels]\n",
      "    scoresAndLabels_rdd = sc.parallelize(scoresAndLabels)\n",
      "    metrics = BinaryClassificationMetrics(scoresAndLabels_rdd)\n",
      "    all_models_metrics.append((model.__class__.__name__,metrics.areaUnderROC, metrics.areaUnderPR))\n",
      "for model_name, AUC, PR in all_models_metrics:\n",
      "    print '%s\u7684AUC\u662f%f,PR\u662f%f'%(model_name, AUC, PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LogisticRegressionModel\u7684AUC\u662f0.620190,PR\u662f0.727701\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "category_dict = {}\n",
      "categories = records.map(lambda x: x[3]).distinct().zipWithIndex().collect()\n",
      "for  (x,y) in [(key.replace('\\\"','') ,val) for (key, val) in categories]:\n",
      "    category_dict[x] = y\n",
      "\n",
      "print '\u7c7b\u522b\u7684\u7f16\u7801:',category_dict\n",
      "\n",
      "num_categories = len(category_dict)\n",
      "print '\u7c7b\u522b\u6570:',num_categories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u7c7b\u522b\u7684\u7f16\u7801: {u'gaming': 1, u'recreation': 0, u'business': 6, u'computer_internet': 3, u'unknown': 11, u'culture_politics': 12, u'science_technology': 8, u'law_crime': 10, u'sports': 5, u'religion': 9, u'weather': 13, u'health': 7, u'?': 4, u'arts_entertainment': 2}\n",
        "\u7c7b\u522b\u6570: 14\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "otherdata = trimmed.map(lambda x : (x[-1],x[4:-1])).\\\n",
      "                    map(lambda (x,y):(x.replace('\\\"',''),[0.0 if yy=='\\\"?\\\"' else yy.replace('\\\"','') for yy in y])).\\\n",
      "                    map(lambda (x,y):(x.replace(\"\\\"\",\"\"),[0.0 if yy =='?' else yy.replace(\"\\\"\",\"\") for yy in y])).\\\n",
      "                    map(lambda (x,y):(int(x), [float(yy) for yy in y])).\\\n",
      "                    map(lambda (x,y):LabeledPoint(x,Vectors.dense(y)))\n",
      "otherdata.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "[LabeledPoint(0.0, [0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575]),\n",
        " LabeledPoint(1.0, [0.574147,3.677966102,0.50802139,0.288770053,0.213903743,0.144385027,0.468648998,0.0,0.0,0.098707403,0.0,0.203489628,0.088652482,1.0,1.0,40.0,0.0,4973.0,187.0,9.0,0.181818182,0.125448029]),\n",
        " LabeledPoint(1.0, [0.996526,2.382882883,0.562015504,0.321705426,0.120155039,0.042635659,0.525448029,0.0,0.0,0.072447859,0.0,0.22640177,0.120535714,1.0,1.0,55.0,0.0,2240.0,258.0,11.0,0.166666667,0.057613169]),\n",
        " LabeledPoint(1.0, [0.801248,1.543103448,0.4,0.1,0.016666667,0.0,0.480724749,0.0,0.0,0.095860566,0.0,0.265655744,0.035343035,1.0,0.0,24.0,0.0,2737.0,120.0,5.0,0.041666667,0.100858369]),\n",
        " LabeledPoint(0.0, [0.719157,2.676470588,0.5,0.222222222,0.12345679,0.043209877,0.446143274,0.0,0.0,0.024908425,0.0,0.228887247,0.050473186,1.0,1.0,14.0,0.0,12032.0,162.0,10.0,0.098765432,0.082568807])]"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u5c06\u7c7b\u522b\u7279\u5f81\u548c\u6570\u503c\u7279\u5f81\u5408\u5e76\n",
      "def build_feature(x):\n",
      "    import numpy as np\n",
      "    numeric_feature = [0.0 if yy=='?' else yy for yy in [y.replace('\\\"','') for y in x[4:-1]]]  #\u6570\u503c\u7279\u5f81\n",
      "    category_feature = np.zeros(num_categories)              #\u6570\u503c\u7279\u5f81\n",
      "    category_index = category_dict[x[3].replace('\\\"','')]    \n",
      "    category_feature[category_index] = 1                     #\u7c7b\u522b\u7279\u5f81\n",
      "    label = x[-1].replace('\\\"','')                           #\u6837\u672c\u6807\u7b7e\n",
      "    feature = LabeledPoint(label, Vectors.dense(list(category_feature)+numeric_feature))   #\u5408\u5e76\u7c7b\u522b\u7279\u5f81\u548c\u6570\u503c\u7279\u5f81\n",
      "    return feature\n",
      "\n",
      "category_data = trimmed.map(lambda x:build_feature(x))\n",
      "category_data.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "[LabeledPoint(0.0, [0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575]),\n",
        " LabeledPoint(1.0, [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.574147,3.677966102,0.50802139,0.288770053,0.213903743,0.144385027,0.468648998,0.0,0.0,0.098707403,0.0,0.203489628,0.088652482,1.0,1.0,40.0,0.0,4973.0,187.0,9.0,0.181818182,0.125448029]),\n",
        " LabeledPoint(1.0, [0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.996526,2.382882883,0.562015504,0.321705426,0.120155039,0.042635659,0.525448029,0.0,0.0,0.072447859,0.0,0.22640177,0.120535714,1.0,1.0,55.0,0.0,2240.0,258.0,11.0,0.166666667,0.057613169]),\n",
        " LabeledPoint(1.0, [0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.801248,1.543103448,0.4,0.1,0.016666667,0.0,0.480724749,0.0,0.0,0.095860566,0.0,0.265655744,0.035343035,1.0,0.0,24.0,0.0,2737.0,120.0,5.0,0.041666667,0.100858369]),\n",
        " LabeledPoint(0.0, [0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.719157,2.676470588,0.5,0.222222222,0.12345679,0.043209877,0.446143274,0.0,0.0,0.024908425,0.0,0.228887247,0.050473186,1.0,1.0,14.0,0.0,12032.0,162.0,10.0,0.098765432,0.082568807])]"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "category_labels = category_data.map(lambda point: point.label)\n",
      "category_features = category_data.map(lambda point: point.features)\n",
      "scaler2 = StandardScaler(withMean=True, withStd=True).fit(category_features)\n",
      "print '\u89c4\u8303\u5316\u4e4b\u524d\u7684\u6570\u636e\u96c6\u7279\u5f81:',category_features.take(5)\n",
      "scaled_category_data = category_labels.zip(scaler2.transform(category_features))\n",
      "scaled_category_data = scaled_category_data.map(lambda (x,y): LabeledPoint(x,y))\n",
      "print '\u89c4\u8303\u5316\u4e4b\u540e\u7684\u6570\u636e\u96c6\u7279\u5f81:',scaled_category_data.map(lambda point: point.features).take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u89c4\u8303\u5316\u4e4b\u524d\u7684\u6570\u636e\u96c6\u7279\u5f81: [DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7891, 2.0556, 0.6765, 0.2059, 0.0471, 0.0235, 0.4438, 0.0, 0.0, 0.0908, 0.0, 0.2458, 0.0039, 1.0, 1.0, 24.0, 0.0, 5424.0, 170.0, 8.0, 0.1529, 0.0791]), DenseVector([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5741, 3.678, 0.508, 0.2888, 0.2139, 0.1444, 0.4686, 0.0, 0.0, 0.0987, 0.0, 0.2035, 0.0887, 1.0, 1.0, 40.0, 0.0, 4973.0, 187.0, 9.0, 0.1818, 0.1254]), DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9965, 2.3829, 0.562, 0.3217, 0.1202, 0.0426, 0.5254, 0.0, 0.0, 0.0724, 0.0, 0.2264, 0.1205, 1.0, 1.0, 55.0, 0.0, 2240.0, 258.0, 11.0, 0.1667, 0.0576]), DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8012, 1.5431, 0.4, 0.1, 0.0167, 0.0, 0.4807, 0.0, 0.0, 0.0959, 0.0, 0.2657, 0.0353, 1.0, 0.0, 24.0, 0.0, 2737.0, 120.0, 5.0, 0.0417, 0.1009]), DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7192, 2.6765, 0.5, 0.2222, 0.1235, 0.0432, 0.4461, 0.0, 0.0, 0.0249, 0.0, 0.2289, 0.0505, 1.0, 1.0, 14.0, 0.0, 12032.0, 162.0, 10.0, 0.0988, 0.0826])]\n",
        "\u89c4\u8303\u5316\u4e4b\u540e\u7684\u6570\u636e\u96c6\u7279\u5f81:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [DenseVector([-0.4464, -0.1019, -0.3818, -0.2042, -0.6808, -0.2327, 2.7207, -0.271, -0.2017, -0.0991, -0.0649, -0.0285, -0.2205, -0.0233, 1.1376, -0.0819, 1.0251, -0.0559, -0.4689, -0.3543, -0.3175, 0.3385, 0.0, 0.8288, -0.1473, 0.2296, -0.1416, 0.7902, 0.7172, -0.298, -0.2035, -0.033, -0.0488, 0.9401, -0.1087, -0.2788]), DenseVector([2.2397, -0.1019, -0.3818, -0.2042, -0.6808, -0.2327, -0.3675, -0.271, -0.2017, -0.0991, -0.0649, -0.0285, -0.2205, -0.0233, 0.4887, 0.1063, 0.1959, 0.509, 1.2695, 1.3097, -0.3132, 0.3385, 0.0, 1.0202, -0.1473, -0.5771, -0.0975, 0.7902, 0.7172, 0.4866, -0.2035, -0.0838, 0.0459, 1.2494, 0.0489, 0.3058]), DenseVector([-0.4464, -0.1019, -0.3818, -0.2042, -0.6808, -0.2327, -0.3675, 3.6896, -0.2017, -0.0991, -0.0649, -0.0285, -0.2205, -0.0233, 1.7637, -0.044, 0.4617, 0.7334, 0.2927, -0.0912, -0.3032, 0.3385, 0.0, 0.3867, -0.1473, -0.1405, -0.0808, 0.7902, 0.7172, 1.2221, -0.2035, -0.3917, 0.4416, 1.868, -0.0338, -0.5504]), DenseVector([-0.4464, -0.1019, -0.3818, -0.2042, -0.6808, -0.2327, -0.3675, 3.6896, -0.2017, -0.0991, -0.0649, -0.0285, -0.2205, -0.0233, 1.1742, -0.1414, -0.3359, -0.7774, -0.7856, -0.6783, -0.3111, 0.3385, 0.0, 0.9516, -0.1473, 0.6073, -0.1252, 0.7902, -1.3941, -0.298, -0.2035, -0.3357, -0.3274, 0.0122, -0.7158, -0.0046]), DenseVector([-0.4464, -0.1019, -0.3818, -0.2042, -0.6808, 4.2963, -0.3675, -0.271, -0.2017, -0.0991, -0.0649, -0.0285, -0.2205, -0.0233, 0.9264, -0.0099, 0.1564, 0.0555, 0.3271, -0.0833, -0.3171, 0.3385, 0.0, -0.7604, -0.1473, -0.0932, -0.1174, 0.7902, 0.7172, -0.7884, -0.2035, 0.7116, -0.0934, 1.5587, -0.4043, -0.2354])]\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u8ba1\u7b97\u6a21\u578b\u51c6\u786e\u7387\n",
      "lrModel_category_scaled = LogisticRegressionWithSGD.train(scaled_category_data, numIteration)\n",
      "lr_totalCorrect_category_scaled = scaled_category_data.\\\n",
      "                   map(lambda point : 1 if(lrModel_category_scaled.predict(point.features)==point.label) else 0).sum()\n",
      "lr_accuracy_category_scaled = lr_totalCorrect_category_scaled/(1.0*data.count())\n",
      "print '\u903b\u8f91\u56de\u5f52\u6a21\u578b\u7684\u51c6\u786e\u7387 : %f'%lr_accuracy_category_scaled"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u903b\u8f91\u56de\u5f52\u6a21\u578b\u7684\u51c6\u786e\u7387 : 0.665720\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u8ba1\u7b97\u6a21\u578b\u7684AUC\u548cPR\n",
      "all_models_metrics =[]\n",
      "for model in [lrModel_category_scaled]:\n",
      "    scoresAndLabels = scaled_category_data.map(lambda point:(model.predict(point.features),point.label)).collect()\n",
      "    scoresAndLabels = [(float(i),j) for (i,j) in scoresAndLabels]\n",
      "    scoresAndLabels_rdd = sc.parallelize(scoresAndLabels)\n",
      "    metrics = BinaryClassificationMetrics(scoresAndLabels_rdd)\n",
      "    all_models_metrics.append((model.__class__.__name__,metrics.areaUnderROC, metrics.areaUnderPR))\n",
      "\n",
      "for model_name, AUC, PR in all_models_metrics:\n",
      "    print '%s\u7684AUC\u662f%f,PR\u662f%f'%(model_name, AUC, PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LogisticRegressionModel\u7684AUC\u662f0.665475,PR\u662f0.757982\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "category_nbdata = scaled_category_data\n",
      "category_nbdata_nonegative = category_nbdata.map(lambda point: (point.label,point.features)).\\\n",
      "                                             map(lambda (x,y): (x,[0.0 if yy<0.0 else yy for yy in y])).\\\n",
      "                                             map(lambda (x,y):LabeledPoint(x,Vectors.dense(y)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u8ba1\u7b97\u51c6\u786e\u7387\n",
      "nb_category_model = NaiveBayes.train(category_nbdata_nonegative)\n",
      "nb_category_total_correct = category_nbdata_nonegative.\\\n",
      "                         map(lambda point:1 if (nb_category_model.predict(point.features)==point.label) else 0).sum()\n",
      "\n",
      "nb_category_accuracy = nb_category_total_correct/(1.0*category_nbdata_nonegative.count())\n",
      "print '\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u51c6\u786e\u7387:%f'%nb_category_accuracy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u51c6\u786e\u7387:0.652738\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_models_metrics =[]\n",
      "for model in [nb_category_model]:\n",
      "    scoresAndLabels = category_nbdata_nonegative.map(lambda point:(model.predict(point.features),point.label)).collect()\n",
      "    scoresAndLabels = [(float(i),j) for (i,j) in scoresAndLabels]\n",
      "    scoresAndLabels_rdd = sc.parallelize(scoresAndLabels)\n",
      "    metrics = BinaryClassificationMetrics(scoresAndLabels_rdd)\n",
      "    all_models_metrics.append((model.__class__.__name__,metrics.areaUnderROC, metrics.areaUnderPR))\n",
      "\n",
      "for model_name, AUC, PR in all_models_metrics:\n",
      "    print '%s\u7684AUC\u662f%f,PR\u662f%f'%(model_name, AUC, PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NaiveBayesModel\u7684AUC\u662f0.651468,PR\u662f0.752038\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_with_params(input_data, model, reg_param, num_iter, step_size):\n",
      "    model = model.train(input_data, iterations=num_iter, regParam=reg_param, step=step_size)\n",
      "    return model\n",
      "def create_metrics(tag, input_data, model):\n",
      "    scoresAndLabels_rdd = input_data.map(lambda x: (model.predict(x.features)*1.0,x.label*1.0))\n",
      "    metrics = BinaryClassificationMetrics(scoresAndLabels_rdd)\n",
      "    return tag, metrics.areaUnderROC, metrics.areaUnderPR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u5bf9\u53c2\u6570\u8fed\u4ee3\u6b21\u6570\u8fdb\u884c\u8c03\u4f18\n",
      "for iteration_num in [1,5,10,50]:\n",
      "    model = train_with_params(scaled_category_data, LogisticRegressionWithSGD, 0.0, iteration_num, 1.0)\n",
      "    label, ROC, PR = create_metrics('%d iterations'%iteration_num,scaled_category_data,model)\n",
      "    print '%s,ROC = %f,PR=%f'%(label,ROC,PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 iterations,ROC = 0.649520,PR=0.745886\n",
        "5 iterations,ROC = 0.666161,PR=0.758022"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10 iterations,ROC = 0.665483,PR=0.757964"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50 iterations,ROC = 0.668143,PR=0.760930"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u5bf9\u53c2\u6570\u6b65\u957f\u6b21\u6570\u8fdb\u884c\u8c03\u4f18\n",
      "for step_size in [0.001, 0.01, 0.1, 1.0, 10.0]:\n",
      "    model = train_with_params(scaled_category_data, LogisticRegressionWithSGD, 0.0, 10, step_size)\n",
      "    label, ROC, PR = create_metrics('%2.3f \u7684\u6b65\u957f'%step_size,scaled_category_data,model)\n",
      "    print '%s,ROC = %f,PR=%f'%(label,ROC,PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.001 \u7684\u6b65\u957f,ROC = 0.649659,PR=0.745974\n",
        "0.010 \u7684\u6b65\u957f,ROC = 0.649644,PR=0.746017"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.100 \u7684\u6b65\u957f,ROC = 0.655211,PR=0.750008"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.000 \u7684\u6b65\u957f,ROC = 0.665483,PR=0.757964"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10.000 \u7684\u6b65\u957f,ROC = 0.619228,PR=0.725713"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u5bf9\u53c2\u6570\u6b63\u5219\u5316\u7cfb\u6570\u8fdb\u884c\u8c03\u4f18\n",
      "for reg_param in [0.001, 0.01, 0.1, 1.0, 10.0]:\n",
      "    model = train_with_params(scaled_category_data, LogisticRegressionWithSGD, reg_param, 10, 0.01)\n",
      "    label, ROC, PR = create_metrics('\u6b63\u5219\u5316\u7cfb\u6570%2.3f '%reg_param,scaled_category_data,model)\n",
      "    print '%s,ROC = %f,PR=%f'%(label,ROC,PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u6b63\u5219\u5316\u7cfb\u65700.001 ,ROC = 0.649644,PR=0.746017\n",
        "\u6b63\u5219\u5316\u7cfb\u65700.010 ,ROC = 0.649644,PR=0.746017"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u6b63\u5219\u5316\u7cfb\u65700.100 ,ROC = 0.649644,PR=0.746017"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u6b63\u5219\u5316\u7cfb\u65701.000 ,ROC = 0.649644,PR=0.746017"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\u6b63\u5219\u5316\u7cfb\u657010.000 ,ROC = 0.648979,PR=0.745492"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u51b3\u7b56\u6811\n",
      "def train_with_params_dt(input_data, impurity, maxTreeDepth):\n",
      "    dt_model = DecisionTree.trainClassifier(input_data,numClass,{},impurity, maxDepth=maxTreeDepth)\n",
      "    return dt_model\n",
      "def create_metrics_dt(tag, input_data, model):\n",
      "    predictLabel= model.predict(input_data.map(lambda point: point.features)).collect()\n",
      "    trueLabel = input_data.map(lambda point: point.label).collect()\n",
      "    scoresAndLabels = [(predictLabel[i],true_val) for i, true_val in enumerate(trueLabel)]\n",
      "    scoresAndLabels_rdd = sc.parallelize(scoresAndLabels)\n",
      "    scoresAndLabels_rdd = scoresAndLabels_rdd.map(lambda (x,y): (float(x),float(y)))\n",
      "    dt_metrics = BinaryClassificationMetrics(scoresAndLabels_rdd)\n",
      "    return tag,dt_metrics.areaUnderROC,dt_metrics.areaUnderPR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for depth in [1,2,3,4,5,10,20]:\n",
      "    for im in ['entropy','gini']:\n",
      "        model=train_with_params_dt(data,im,depth)\n",
      "        tag, ROC, PR = create_metrics_dt('impurity: %s, %d maxTreeDepth:'%(im,depth),data,model)\n",
      "        print '%s, AUC=%f, PR=%f'%(tag,ROC,PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "impurity: entropy, 1 maxTreeDepth:, AUC=0.593268, PR=0.749004\n",
        "impurity: gini, 1 maxTreeDepth:, AUC=0.593268, PR=0.749004"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: entropy, 2 maxTreeDepth:, AUC=0.616839, PR=0.725164"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: gini, 2 maxTreeDepth:, AUC=0.616839, PR=0.725164"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: entropy, 3 maxTreeDepth:, AUC=0.626070, PR=0.751813"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: gini, 3 maxTreeDepth:, AUC=0.626070, PR=0.751813"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: entropy, 4 maxTreeDepth:, AUC=0.636333, PR=0.749393"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: gini, 4 maxTreeDepth:, AUC=0.636333, PR=0.749393"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: entropy, 5 maxTreeDepth:, AUC=0.648837, PR=0.743081"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: gini, 5 maxTreeDepth:, AUC=0.648916, PR=0.742894"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: entropy, 10 maxTreeDepth:, AUC=0.762552, PR=0.829623"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: gini, 10 maxTreeDepth:, AUC=0.783709, PR=0.843469"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: entropy, 20 maxTreeDepth:, AUC=0.984537, PR=0.988522"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "impurity: gini, 20 maxTreeDepth:, AUC=0.988707, PR=0.991328"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u6734\u7d20\u8d1d\u53f6\u65af\n",
      "def train_with_params_nb(input_data, lambda_para):\n",
      "    nb_model = NaiveBayes.train(input_data,lambda_para)\n",
      "    return nb_model\n",
      "def create_metrics_nb(tag, nbdata, model):\n",
      "    scoresAndLabels = nbdata.map(lambda point:(float(model.predict(point.features)),point.label))\n",
      "    nb_metrics = BinaryClassificationMetrics(scoresAndLabels)\n",
      "    return tag,nb_metrics.areaUnderROC,nb_metrics.areaUnderPR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u53c2\u6570\u8c03\u4f18\n",
      "for lambda_para in [0.001, 0.01, 0.1, 1.0, 10.0]:\n",
      "    model=train_with_params_nb(nbdata,lambda_para)\n",
      "    tag, ROC, PR = create_metrics_dt('lambda=%f' %lambda_para,nbdata,model)\n",
      "    print '%s, AUC=%f, PR=%f'%(tag,ROC,PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "lambda=0.001000, AUC=0.583697, PR=0.680961\n",
        "lambda=0.010000, AUC=0.583697, PR=0.680961"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lambda=0.100000, AUC=0.583697, PR=0.680961"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lambda=1.000000, AUC=0.583559, PR=0.680851"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lambda=10.000000, AUC=0.583412, PR=0.680762"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u4ea4\u53c9\u9a8c\u8bc1\n",
      "train_test_split = scaled_category_data.randomSplit([0.6,0.4],123)\n",
      "train = train_test_split[0]\n",
      "test = train_test_split[1]\n",
      "for reg_para in [0.001, 0.0025, 0.005, 0.01]:\n",
      "    model = train_with_params(train, LogisticRegressionWithSGD, reg_para,1.0,1.0)\n",
      "    label, ROC, PR = create_metrics('%f regularization parameter'%reg_para,test,model)\n",
      "    print '%s,AUC = %f,PR=%f'%(label,ROC,PR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.001000 regularization parameter,AUC = 0.644375,PR=0.743119\n",
        "0.002500 regularization parameter,AUC = 0.644375,PR=0.743119"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.005000 regularization parameter,AUC = 0.644375,PR=0.743119"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.010000 regularization parameter,AUC = 0.644375,PR=0.743119"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}